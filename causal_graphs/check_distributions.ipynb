{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we check what distribution we obtain with different NN initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from causal_graphs.graph_utils import *\n",
    "from causal_graphs.graph_generation import *\n",
    "from causal_graphs.graph_visualization import *\n",
    "from causal_graphs.variable_distributions import *\n",
    "from causal_discovery.multivariable_mlp import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = generate_categorical_graph(num_vars=100,\n",
    "                                   min_categs=10,\n",
    "                                   max_categs=10,\n",
    "                                   connected=True,\n",
    "                                   graph_func=get_graph_func(\"random_max_10\"),\n",
    "                                   edge_prob=0.008,\n",
    "                                   use_nn=True,\n",
    "                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = graph.sample(batch_size=100000, as_array=True)\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(10, dtype=np.int32)\n",
    "counts = (vals[None,None] == samples[:,:,None]).sum(axis=0)\n",
    "probs = counts / counts.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = -(probs * np.log(probs)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 1.9391802220664622\n",
      "Max 2.235183420993497 93\n",
      "Min 0.8664123797698585 7\n",
      "Median 1.9729833792257185\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", ce.mean())\n",
    "print(\"Max\", ce.max(), ce.argmax())\n",
    "print(\"Min\", ce.min(), ce.argmin())\n",
    "print(\"Median\", np.median(ce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0436 , 0.04264, 0.01012, 0.03379, 0.01609, 0.00133, 0.80769,\n",
       "       0.01728, 0.0179 , 0.00956])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[ce.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4360,  4264,  1012,  3379,  1609,   133, 80769,  1728,  1790,\n",
       "         956])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[ce.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08729, 0.16134, 0.09522, 0.04588, 0.06884, 0.15279, 0.07189,\n",
       "       0.10397, 0.13865, 0.07413])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[ce.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8729, 16134,  9522,  4588,  6884, 15279,  7189, 10397, 13865,\n",
       "        7413])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[ce.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.variables[100].prob_dist.prob_func.embed_module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Check the importance of an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_PATH = '../experiments/checkpoints/array_job_200_7617862/experiment_2/'\n",
    "BASE_PATH = '../experiments/checkpoints/2021_04_29__11_19_38/'\n",
    "graph = CausalDAG.load_from_file(BASE_PATH + 'graph_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = graph.sample(batch_size=100000, as_array=True)\n",
    "samples = torch.from_numpy(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_vars, num_categs):\n",
    "        super().__init__()\n",
    "        self.num_vars = num_vars\n",
    "        if num_vars == 0:\n",
    "            num_vars = 1\n",
    "        self.embedding = nn.Embedding(num_vars*num_categs, 64)\n",
    "        self.embedding.weight.data.mul_(1./math.sqrt(num_vars))\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(64, num_categs),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        pos_trans = torch.arange(num_vars, dtype=torch.long) * num_categs\n",
    "        self.register_buffer(\"pos_trans\", pos_trans, persistent=False)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.num_vars > 0:\n",
    "            embed = self.embedding(x + self.pos_trans[None])\n",
    "            embed = embed.sum(dim=1)\n",
    "        else:\n",
    "            embed = self.embedding(x.new_zeros(x.shape[:-1]))\n",
    "        out = self.net(embed)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = 64\n",
    "node2 = 272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parents tensor([64])\n",
      "Parents excluded tensor([], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "parents = torch.from_numpy(np.where(graph.adj_matrix[:,node2])[0])\n",
    "assert node1 in parents\n",
    "parents_excl = parents[parents != node1]\n",
    "assert node1 not in parents_excl\n",
    "\n",
    "print(\"Parents\", parents)\n",
    "print(\"Parents excluded\", parents_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0597, 0.1461, 0.1488, 0.0287, 0.0363, 0.0838, 0.2011, 0.1309, 0.0604,\n",
      "         0.1041],\n",
      "        [0.0278, 0.0448, 0.0394, 0.1028, 0.1555, 0.2010, 0.1138, 0.1850, 0.1100,\n",
      "         0.0198]])\n"
     ]
    }
   ],
   "source": [
    "vals = torch.arange(10, dtype=torch.long)\n",
    "counts = (vals[None] == samples[:,(node1,node2),None]).sum(dim=0)\n",
    "probs = counts / counts.float().sum(dim=1, keepdims=True)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = SimpleModel(num_vars=parents.shape[0], num_categs=10)\n",
    "model_excl = SimpleModel(num_vars=parents_excl.shape[0], num_categs=10)\n",
    "\n",
    "optim_full = torch.optim.Adam(model_full.parameters(), lr=5e-3)\n",
    "optim_excl = torch.optim.Adam(model_excl.parameters(), lr=5e-3)\n",
    "\n",
    "loss_module = nn.NLLLoss()\n",
    "\n",
    "dataset = data.TensorDataset(samples)\n",
    "data_loader = data.DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=10.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iterations', max=782.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_batch(batch):\n",
    "    out_full = model_full(batch[:,parents])\n",
    "    out_excl = model_excl(batch[:,parents_excl])\n",
    "    labels = batch[:,node2]\n",
    "    loss_full = loss_module(out_full, labels)\n",
    "    loss_excl = loss_module(out_excl, labels)\n",
    "    return loss_full, loss_excl\n",
    "\n",
    "for _ in tqdm(range(10), leave=False, desc=\"Epochs\"):\n",
    "    for batch in tqdm(data_loader, leave=False, desc=\"Iterations\"):\n",
    "        batch = batch[0]\n",
    "        optim_full.zero_grad()\n",
    "        optim_excl.zero_grad()\n",
    "        loss_full, loss_excl = eval_batch(batch)\n",
    "        loss_full.backward()\n",
    "        loss_excl.backward()\n",
    "        optim_full.step()\n",
    "        optim_excl.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL all parents 1.9130173921585083\n",
      "NLL without parents 2.092456340789795\n",
      "Difference 0.17943894863128662\n"
     ]
    }
   ],
   "source": [
    "eval_samples = graph.sample(batch_size=100000, as_array=True)\n",
    "eval_samples = torch.from_numpy(eval_samples)\n",
    "with torch.no_grad():\n",
    "    nll_full, nll_excl = eval_batch(eval_samples)\n",
    "    nll_full, nll_excl = nll_full.item(), nll_excl.item()\n",
    "    print(\"NLL all parents\", nll_full)\n",
    "    print(\"NLL without parents\", nll_excl)\n",
    "    print(\"Difference\", nll_excl-nll_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
