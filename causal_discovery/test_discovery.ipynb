{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Causal Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from multivariable_mlp import *\n",
    "from graph_fitting import *\n",
    "from graph_scoring import *\n",
    "from graph_update import *\n",
    "from graph_discovery import *\n",
    "from causal_graphs.graph_generation import generate_categorical_graph, generate_chain, generate_random_graph\n",
    "from causal_graphs.graph_visualization import visualize_graph\n",
    "from causal_graphs.graph_utils import adj_matrix_to_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable MLP\n",
    "\n",
    "### Layer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_VARS = 4\n",
    "input_data = torch.randn(BATCH_SIZE, NUM_VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = MultivarLinear(c_in=NUM_VARS, c_out=NUM_VARS, extra_dims=[NUM_VARS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "out = linear_layer(input_data)\n",
    "print(\"Out\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(BATCH_SIZE, NUM_VARS)\n",
    "out1 = linear_layer(input_data)\n",
    "input_data[0,0] = -10\n",
    "out2 = linear_layer(input_data)\n",
    "out_equals = (out1 == out2)\n",
    "assert out_equals[1:].all(), \"Batch not independent\"\n",
    "assert (~out_equals[0]).all(), \"Not all inputs were influenced\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask_module = InputMask(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultivarMLP(\n",
      "  (layers): ModuleList(\n",
      "    (0): InputMask()\n",
      "    (1): MultivarLinear(c_in=4, c_out=64, extra_dims=[4])\n",
      "    (2): LeakyReLU(negative_slope=0.1)\n",
      "    (3): MultivarLinear(c_in=64, c_out=64, extra_dims=[4])\n",
      "    (4): LeakyReLU(negative_slope=0.1)\n",
      "    (5): MultivarLinear(c_in=64, c_out=1, extra_dims=[4])\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = MultivarMLP(input_dims=NUM_VARS, \n",
    "                  hidden_dims=[64, 64], \n",
    "                  output_dims=1, \n",
    "                  extra_dims=[NUM_VARS],\n",
    "                  pre_layers=input_mask_module,\n",
    "                  actfn=lambda : nn.LeakyReLU(0.1))\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.bernoulli(torch.zeros(BATCH_SIZE, NUM_VARS, NUM_VARS)+0.5)\n",
    "mask[:,torch.arange(mask.shape[1]),torch.arange(mask.shape[2])] = 0.\n",
    "out = mlp(input_data, mask=mask)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = mlp(input_data, mask=mask)\n",
    "out_equal = (out == out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGS = 10\n",
    "input_data = torch.randint(NUM_CATEGS, size=(BATCH_SIZE, NUM_VARS), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbedLayer(\n",
      "  (input_mask): InputMask()\n",
      "  (embedding): Embedding(160, 64)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embed = EmbedLayer(num_vars=NUM_VARS,\n",
    "                   num_categs=NUM_CATEGS,\n",
    "                   hidden_dim=64,\n",
    "                   input_mask=input_mask_module,\n",
    "                   share_embeds=False,\n",
    "                   sparse_embeds=True)\n",
    "print(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 64])\n",
      "tensor([0.9217, 1.2478, 0.9326, 0.7497, 0.6657, 0.6379, 0.6909, 1.0763, 0.3857,\n",
      "        0.8445, 0.5484, 0.9653, 0.9020, 1.2382, 0.8558, 1.0464, 2.1659, 2.1048,\n",
      "        1.4442, 0.7675, 0.8855, 0.9104, 1.3654, 1.3076, 1.7468, 1.4325, 0.6232,\n",
      "        0.9345, 0.5947, 1.1745, 1.1164, 0.3979, 0.6818, 1.9140, 1.1503, 1.1840,\n",
      "        0.9970, 0.3121, 0.8908, 0.7076, 1.0906, 0.7537, 1.3655, 1.3164, 1.9447,\n",
      "        0.7903, 1.4882, 1.4770, 0.4753, 1.4019, 1.8230, 1.4317, 0.4038, 1.2740,\n",
      "        1.2223, 1.8110, 0.8602, 1.1388, 0.8527, 0.6196, 0.7831, 0.5557, 0.8361,\n",
      "        1.3762], grad_fn=<StdBackward1>)\n",
      "tensor([[[ 0.4782, -1.0840,  0.8132,  1.6424,  0.2828,  1.1481,  1.0430,\n",
      "           2.7088, -0.7327, -0.0379,  0.0641, -0.9786,  0.3501, -1.3878,\n",
      "          -1.2287, -0.8569,  1.3064, -1.7483, -0.9376,  0.2871, -1.1425,\n",
      "          -0.1643, -3.6239, -3.5391, -1.4775,  1.5825,  0.1483,  1.9029,\n",
      "           0.3089,  0.1018,  0.9233,  0.7635, -0.0615,  1.6846,  2.1429,\n",
      "           1.6808, -0.1719, -0.4374, -0.6207,  0.0323, -1.2536, -1.8094,\n",
      "           2.1942, -3.2416,  3.1880,  1.6173, -1.0957,  0.9962,  0.9390,\n",
      "           0.5457, -0.9662, -0.9576, -0.2665, -2.7808,  1.8108,  1.1025,\n",
      "           0.9097,  2.7085, -0.9617,  0.5535, -0.8359,  0.8472, -0.4445,\n",
      "          -0.1322],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000],\n",
      "         [ 1.4935,  0.0556, -1.0737, -0.1163, -1.1575,  0.7069,  0.8876,\n",
      "           0.7828, -0.0855, -1.6889,  1.3529, -0.4394, -0.0266,  2.4647,\n",
      "          -0.1185, -0.7423, -2.6867,  2.9094,  0.7888, -0.8368,  0.9398,\n",
      "           2.3878, -0.6279,  0.5756, -1.7129,  1.8701, -0.9250,  0.2815,\n",
      "           0.5828,  0.7805,  1.9107,  0.5102, -1.2901, -1.5690,  0.4114,\n",
      "          -0.3790, -1.5385,  0.6211,  1.0094,  1.1906, -1.9576,  0.8341,\n",
      "          -2.6791, -0.4936,  4.2040, -0.5793,  3.9039, -2.8341,  0.6094,\n",
      "          -1.2089, -3.2460,  3.8024,  0.3408,  1.5442,  1.0170,  0.4693,\n",
      "           1.8912, -0.8307,  0.1978, -0.0587,  1.1626,  0.5015,  0.3187,\n",
      "           0.7006],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000]],\n",
      "\n",
      "        [[-0.5660, -2.0033,  0.7824, -1.0768,  1.1332, -0.4589, -0.6625,\n",
      "          -0.3664,  0.6778, -0.6920,  0.6024, -0.2003, -0.4063, -0.5857,\n",
      "           1.1640,  1.0828,  1.5976,  4.2517, -3.2403,  1.4838, -0.7577,\n",
      "          -0.3222, -0.8821,  0.2589,  0.9447,  0.6416, -0.7338, -0.5910,\n",
      "          -1.0180, -0.8293, -1.5388,  0.5197,  0.0124, -2.6321,  0.8683,\n",
      "          -1.3350,  0.6506, -0.1682,  1.6696,  1.6780, -1.4611, -0.1091,\n",
      "          -0.8107,  0.7974, -0.6909, -0.9646,  0.7267, -1.4292,  0.9211,\n",
      "          -0.7562,  2.7921,  1.2211,  0.1171, -1.1998,  0.4316, -1.0256,\n",
      "           1.6339,  1.1031, -1.5668,  0.5901,  1.3821, -0.8638,  0.3979,\n",
      "           1.9697],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000],\n",
      "         [ 0.3616,  1.9744, -1.6944, -0.2169,  0.4378, -0.7465, -0.7156,\n",
      "          -0.8487, -0.0668, -0.9509,  0.3754, -1.6702,  2.1758,  0.0064,\n",
      "           1.5696,  2.2133, -4.7475, -1.7716,  1.5811, -1.0188,  1.6661,\n",
      "           0.0666, -1.2819, -0.3996, -0.3447, -2.4469,  0.5620,  1.8329,\n",
      "           0.8438,  2.7022,  0.7298,  1.0671, -0.7730,  3.6117,  3.1209,\n",
      "          -2.0992,  0.5390, -0.2887,  1.8536, -0.3949,  1.4638, -0.3238,\n",
      "           0.1801,  0.2724, -0.4664,  0.3380, -0.2064, -0.7755, -0.1117,\n",
      "          -1.0407, -0.9595,  0.5138, -0.6576,  0.0708,  1.9603, -4.7803,\n",
      "          -0.3230, -0.3149,  1.2560,  1.0749,  1.1866, -0.5876, -0.7139,\n",
      "          -2.1257],\n",
      "         [-1.7426, -1.6515, -1.2295,  0.2007, -0.4622,  0.7001, -0.7197,\n",
      "           0.5518, -0.2424, -2.1298, -0.4763,  1.6915, -0.9194, -1.5932,\n",
      "          -0.0603, -0.6649,  0.7688,  0.0793, -1.0623, -0.3542,  0.2572,\n",
      "          -0.4887,  0.9295,  0.1035,  3.9314, -1.4040,  0.9933,  1.1497,\n",
      "           0.7494,  1.9542,  1.7653,  0.2400,  1.0611, -0.6310,  1.3123,\n",
      "           0.9169,  2.0333, -0.1052,  0.1987,  0.2427, -0.8218, -0.6467,\n",
      "           0.6327, -1.7678, -1.1075,  0.7354,  0.7651,  2.0271, -0.2100,\n",
      "           3.2275,  1.7671,  0.1601,  0.7184,  0.4892, -1.8745, -1.0594,\n",
      "           1.2780, -0.5454, -0.6970, -1.0181,  0.0411,  0.3277,  2.0625,\n",
      "           2.2950]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = embed(input_data, mask=mask)\n",
    "print(out.shape)\n",
    "print(out.flatten(0,1).std(0))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 64])\n",
      "tensor([0.7945, 2.2059, 1.9231, 2.2923, 1.2264, 1.0312, 1.4934, 1.6251, 2.2076,\n",
      "        1.2514, 1.0858, 1.8541, 1.8954, 3.4863, 2.0298, 1.5322, 3.6553, 2.3711,\n",
      "        1.6388, 1.7063, 2.8773, 2.4683, 2.0014, 1.4685, 1.5479, 1.8328, 1.2035,\n",
      "        2.6172, 0.5401, 0.9879, 1.8226, 1.0069, 1.9381, 2.4227, 2.2222, 2.0826,\n",
      "        1.0361, 2.4461, 1.2708, 1.5977, 2.2510, 0.8937, 2.7040, 2.5244, 1.8126,\n",
      "        0.5556, 1.7591, 1.0348, 1.0649, 1.8053, 2.0368, 2.1577, 2.1166, 1.4252,\n",
      "        1.2361, 1.5452, 2.0223, 0.6172, 1.5423, 1.5789, 1.4353, 1.8903, 2.1281,\n",
      "        1.8252], grad_fn=<StdBackward1>)\n",
      "tensor([[[-4.5362e-01,  1.5029e+00,  4.3225e-01,  1.6117e+00, -6.0602e-01,\n",
      "           2.0990e+00,  5.0617e-01,  5.3775e+00,  3.5724e-01, -2.0461e+00,\n",
      "           7.8914e-01,  2.5200e-02,  3.4035e-01, -2.1932e+00, -7.8100e-01,\n",
      "           1.3508e+00,  1.1449e+00, -4.0495e+00, -2.2813e+00, -4.4673e-01,\n",
      "          -3.5669e+00,  2.2372e+00, -2.5506e+00, -2.0740e+00, -1.2954e+00,\n",
      "           1.1910e+00,  2.1902e+00,  3.8816e+00,  1.7238e+00,  9.3656e-01,\n",
      "           6.3939e-01,  1.7099e+00, -7.5316e-04,  2.4588e+00,  4.3962e+00,\n",
      "           2.0769e+00, -1.9385e-01,  7.1403e-01,  1.1545e+00,  7.0083e-01,\n",
      "          -2.6150e+00, -1.1425e+00,  2.7769e+00, -6.3703e+00,  2.5150e+00,\n",
      "           5.5486e-01,  3.2509e-01, -1.2691e-01, -1.8031e+00, -2.0423e+00,\n",
      "          -9.8190e-01, -6.7825e-01, -5.6592e-01, -2.4491e+00,  2.3817e+00,\n",
      "          -1.5842e-01,  3.2380e+00,  1.0411e+00, -1.1451e-01,  3.6819e+00,\n",
      "          -1.3222e+00,  3.3101e+00, -2.7508e+00, -1.1726e+00],\n",
      "         [-3.9970e-01,  2.3659e+00,  2.9171e+00, -4.4641e+00, -6.0642e-01,\n",
      "           2.6537e-01, -9.2801e-01,  3.9042e+00, -4.6970e+00,  3.1414e-01,\n",
      "          -1.1968e+00,  2.3125e+00, -2.5829e-01,  4.1680e+00,  2.5570e+00,\n",
      "          -7.1804e-01,  2.9710e+00,  4.4192e-01, -9.7954e-01, -3.1526e+00,\n",
      "           4.4870e+00, -3.8579e+00, -2.5388e+00,  1.7025e+00, -1.9872e+00,\n",
      "           1.3210e+00, -5.3965e-01, -7.3349e-01,  2.1583e+00,  3.4237e-01,\n",
      "          -4.5385e-01,  2.0760e-01, -3.7968e+00,  9.1549e-02, -1.4479e+00,\n",
      "           5.4642e-01, -4.0349e-01, -4.9556e+00,  2.9373e-01,  3.8958e+00,\n",
      "          -4.2495e+00, -7.7108e-01, -2.4967e+00,  1.0674e-01, -1.1385e+00,\n",
      "          -5.2953e-01,  1.5008e+00,  1.0127e+00, -2.5577e+00,  1.6649e-01,\n",
      "          -1.4033e+00, -1.6035e+00, -1.4257e+00,  1.3137e-01,  5.0905e-01,\n",
      "          -1.3309e+00,  2.2358e+00,  4.4604e-01,  1.6592e+00,  3.2415e+00,\n",
      "           1.8037e-02, -1.8927e+00,  7.4777e-02,  9.5222e-01],\n",
      "         [-7.2088e-01,  1.1925e+00,  7.9698e-01,  3.7743e-01, -2.9625e-01,\n",
      "           4.9127e-01,  2.8667e+00,  1.2936e+00,  1.2245e-01, -2.9369e+00,\n",
      "           1.6896e+00, -1.7918e+00, -3.3638e-01,  5.2573e-02, -1.5306e-01,\n",
      "           5.2870e-01, -4.8927e+00,  2.5488e+00,  3.6972e-01,  6.0843e-02,\n",
      "           4.0184e-01,  2.4099e+00,  9.4323e-01,  1.3690e-01, -3.4253e-01,\n",
      "           2.2045e+00, -1.7686e+00,  3.5529e+00,  1.6001e+00,  9.7000e-02,\n",
      "           1.6416e+00,  2.2036e+00, -1.5841e+00, -6.1453e-01, -2.4126e-01,\n",
      "          -2.7259e-01, -1.7741e+00,  1.3135e+00,  5.5989e-01,  1.7914e+00,\n",
      "          -4.1588e+00, -2.4068e+00, -3.1650e+00, -3.2254e+00,  2.0957e+00,\n",
      "           2.2430e-01,  4.7306e+00, -4.8858e-01, -7.7607e-01, -1.2677e+00,\n",
      "          -3.8327e+00,  3.6709e+00,  1.1429e+00,  1.2492e+00,  5.6019e-01,\n",
      "          -1.0898e+00, -1.6124e+00, -5.4785e-01, -2.3188e+00,  1.0246e+00,\n",
      "           1.2166e+00, -4.3187e-01, -1.3626e+00,  1.0656e+00],\n",
      "         [-6.3597e-01, -2.2014e+00, -9.6286e-01, -4.4341e-01,  2.3486e+00,\n",
      "          -1.4780e+00, -2.2951e+00,  2.1232e+00, -5.8091e-02, -1.4507e+00,\n",
      "           1.2992e+00,  1.3619e+00, -2.4103e+00, -4.6565e+00, -1.8462e+00,\n",
      "          -2.1319e+00,  1.9837e-01, -2.3377e-01,  3.1420e-01,  1.8969e+00,\n",
      "           1.6750e+00,  1.1309e+00,  2.4448e+00,  7.9166e-01, -1.6021e+00,\n",
      "          -1.0652e+00, -6.1213e-02, -2.3180e+00,  1.3175e+00, -8.3792e-01,\n",
      "           5.8546e-01,  2.6311e+00,  1.1446e+00, -2.4786e+00, -1.6651e+00,\n",
      "          -6.5558e-01, -2.4604e+00, -3.3811e+00, -8.7474e-01,  2.4202e-01,\n",
      "           1.0273e+00, -2.7881e+00,  2.6972e+00, -2.0904e+00, -1.2304e+00,\n",
      "           4.8798e-01,  5.1522e+00,  1.8923e-02, -1.0295e+00, -7.0081e-01,\n",
      "           6.4941e-01,  3.0991e+00,  3.6466e+00, -2.3800e+00,  1.2887e+00,\n",
      "           5.7767e-01,  2.7295e+00,  2.6416e-01,  7.5589e-01,  8.5458e-01,\n",
      "           3.4906e+00, -2.2557e+00,  1.1405e+00, -2.3366e+00]],\n",
      "\n",
      "        [[-7.1368e-01, -1.2320e+00,  9.0306e-01,  1.2044e-01, -9.4419e-01,\n",
      "           1.0628e-01, -2.5778e-01,  2.0236e+00,  2.6619e-01, -2.9097e+00,\n",
      "           9.5516e-01,  1.2056e+00,  1.3057e+00, -3.0319e+00,  4.6564e-01,\n",
      "           2.2583e+00,  3.6182e+00,  2.4862e+00, -3.6076e+00,  2.7935e-01,\n",
      "          -2.4016e+00,  8.1960e-01,  6.7815e-02,  1.5239e+00,  6.9839e-02,\n",
      "           8.3570e-01, -9.8507e-01, -1.2889e+00,  1.5274e+00, -1.3047e+00,\n",
      "          -2.9167e+00,  2.1938e+00, -7.7266e-01, -1.6998e+00,  1.3917e+00,\n",
      "           3.8453e-01,  4.5803e-02, -5.2136e-01,  3.3067e+00,  3.1006e+00,\n",
      "          -2.1325e+00, -1.4761e-01,  2.1105e-01,  9.6239e-01, -1.1307e+00,\n",
      "           7.4733e-02,  2.5184e+00, -1.7307e+00,  5.1530e-01, -3.2713e+00,\n",
      "           5.2046e-01,  2.9231e+00,  2.4311e+00, -1.2396e+00, -5.1120e-01,\n",
      "          -3.3035e+00,  2.5338e+00, -8.9859e-01, -1.4382e+00,  2.0615e+00,\n",
      "           1.4395e+00,  5.1981e-01, -9.2090e-01,  2.5055e+00],\n",
      "         [-3.9970e-01,  2.3659e+00,  2.9171e+00, -4.4641e+00, -6.0642e-01,\n",
      "           2.6537e-01, -9.2801e-01,  3.9042e+00, -4.6970e+00,  3.1414e-01,\n",
      "          -1.1968e+00,  2.3125e+00, -2.5829e-01,  4.1680e+00,  2.5570e+00,\n",
      "          -7.1804e-01,  2.9710e+00,  4.4192e-01, -9.7954e-01, -3.1526e+00,\n",
      "           4.4870e+00, -3.8579e+00, -2.5388e+00,  1.7025e+00, -1.9872e+00,\n",
      "           1.3210e+00, -5.3965e-01, -7.3349e-01,  2.1583e+00,  3.4237e-01,\n",
      "          -4.5385e-01,  2.0760e-01, -3.7968e+00,  9.1549e-02, -1.4479e+00,\n",
      "           5.4642e-01, -4.0349e-01, -4.9556e+00,  2.9373e-01,  3.8958e+00,\n",
      "          -4.2495e+00, -7.7108e-01, -2.4967e+00,  1.0674e-01, -1.1385e+00,\n",
      "          -5.2953e-01,  1.5008e+00,  1.0127e+00, -2.5577e+00,  1.6649e-01,\n",
      "          -1.4033e+00, -1.6035e+00, -1.4257e+00,  1.3137e-01,  5.0905e-01,\n",
      "          -1.3309e+00,  2.2358e+00,  4.4604e-01,  1.6592e+00,  3.2415e+00,\n",
      "           1.8037e-02, -1.8927e+00,  7.4777e-02,  9.5222e-01],\n",
      "         [ 9.1306e-01,  3.0333e+00, -5.8000e-02,  5.5001e-01,  1.3280e+00,\n",
      "          -7.1175e-01, -3.1385e-02,  3.2329e-01, -8.7458e-01, -1.6708e+00,\n",
      "           8.6044e-01, -2.5935e+00,  6.7319e-01, -2.4321e+00,  3.3021e+00,\n",
      "           1.1674e+00, -5.8731e+00, -3.1003e+00,  1.6123e+00, -7.4699e-01,\n",
      "           1.5986e+00,  4.2599e-01, -1.5114e-01, -1.6326e+00,  5.1020e-01,\n",
      "          -1.6685e+00,  6.3158e-01,  4.2765e+00,  1.2846e+00,  1.1634e+00,\n",
      "          -2.0218e+00,  2.2925e+00, -2.0016e+00,  4.1947e+00,  2.7469e+00,\n",
      "          -3.8503e+00,  2.3635e-01, -5.6344e-01,  1.3649e+00,  3.0978e-01,\n",
      "           6.3393e-01, -1.5159e+00, -6.8369e-01,  1.0405e+00, -9.5327e-01,\n",
      "          -9.8822e-01,  1.0918e+00,  1.2725e-01, -3.6924e-01, -1.9580e+00,\n",
      "          -1.3110e+00,  1.8090e+00,  4.8865e-01,  3.4471e-01,  3.3619e+00,\n",
      "          -4.0301e+00, -2.0288e+00,  2.9292e-01, -6.3521e-01,  1.4118e+00,\n",
      "           6.4230e-01, -2.1360e+00, -2.2679e+00, -2.6334e+00],\n",
      "         [-2.0197e+00, -2.4889e+00, -2.8909e+00, -6.0819e-01,  1.2696e+00,\n",
      "           4.9794e-01, -6.7893e-01,  2.6638e+00,  1.8917e-01, -1.4936e+00,\n",
      "           6.5116e-01,  1.6084e+00, -4.5355e+00, -4.0957e+00, -1.7297e+00,\n",
      "          -1.5156e+00,  1.8725e+00, -9.8760e-01, -1.3053e+00, -6.0251e-01,\n",
      "           7.1723e-01, -2.4355e-02,  1.6297e+00,  4.7706e-01,  2.5222e+00,\n",
      "          -3.0460e+00,  5.4239e-01,  1.3660e+00,  4.7909e-01,  1.6290e+00,\n",
      "           2.6109e+00,  5.9008e-01,  1.0145e+00, -2.8455e+00, -3.7725e-01,\n",
      "           3.2371e+00,  5.5570e-01, -1.1797e+00, -3.1762e-01,  5.6005e-01,\n",
      "           4.9725e-02, -1.8653e+00,  3.6372e+00, -1.5518e+00, -2.7857e+00,\n",
      "           2.2415e-01,  3.4762e+00,  1.5540e+00, -9.8583e-01,  2.6246e+00,\n",
      "           3.1194e+00,  4.3011e-01,  3.7943e+00, -2.0521e+00,  5.3583e-01,\n",
      "          -2.4316e+00,  1.3337e+00,  4.4546e-01, -1.8306e+00, -1.0354e+00,\n",
      "           1.7707e+00, -4.5332e-01,  3.9387e+00,  5.7052e-01]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embed.sparse_embeds = False\n",
    "out = embed(input_data, mask=mask)\n",
    "print(out.shape)\n",
    "print(out.flatten(0,1).std(0))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'actfn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0ef30d58908e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0moutput_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CATEGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mextra_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNUM_VARS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   pre_layers=embed)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'actfn'"
     ]
    }
   ],
   "source": [
    "mlp = MultivarMLP(input_dims=embed.output_dim, \n",
    "                  hidden_dims=[64, 64], \n",
    "                  output_dims=NUM_CATEGS, \n",
    "                  extra_dims=[NUM_VARS],\n",
    "                  pre_layers=embed)\n",
    "mlp.eval()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mlp(input_data, mask=mask)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(8, 3, 2)\n",
    "a.chunk(5, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, graph, dataset_size):\n",
    "        super().__init__()\n",
    "        self.graph = graph\n",
    "        self.var_names = [v.name for v in self.graph.variables]\n",
    "        data = graph.sample(batch_size=dataset_size, as_array=True)\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = generate_categorical_graph(num_vars=NUM_VARS,\n",
    "                                   min_categs=NUM_CATEGS,\n",
    "                                   max_categs=NUM_CATEGS,\n",
    "                                   edge_prob=0.0,\n",
    "                                   connected=True,\n",
    "                                   seed=42)\n",
    "visualize_graph(graph, show_plot=True, figsize=(3, 2), layout=\"circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CategoricalData(graph, dataset_size=64*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_vars=NUM_VARS, num_categs=NUM_CATEGS, hidden_dims=[64, 64])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittingModule = GraphFitting(model, optimizer, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = nn.Parameter(torch.randn(NUM_VARS, NUM_VARS))\n",
    "sample_matrix = torch.sigmoid(gamma).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = 0\n",
    "for _ in tqdm(range(100)):\n",
    "    avg_loss += fittingModule.fit_step(sample_matrix)\n",
    "print(\"Average loss\", avg_loss / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoringModule = GraphScoring(model=model, graph=graph, N_s=4, C_s=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammagrad, logregret, var_idx = scoringModule.score(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variable to perform intervention on:\", var_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape\", gammagrad.shape, logregret.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateModule = GraphUpdate(lambda_sparse=0.1, lambda_DAG=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updateModule.update(gammagrad, logregret, gamma, var_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VARS = 3\n",
    "toy_graph = generate_categorical_graph(num_vars=NUM_VARS, min_categs=3, max_categs=3, graph_func=generate_random_graph, edge_prob=0.4, seed=0)\n",
    "visualize_graph(toy_graph, show_plot=True, figsize=(2, 2), layout=\"graphviz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(inputs, batch_size):\n",
    "    return np.ones((3,))/3\n",
    "\n",
    "print(toy_graph.variables[0])\n",
    "toy_graph.variables[0].prob_dist.prob_func = uniform\n",
    "for i in range(3):\n",
    "    print(\"Output %i: %4.2f\" % (i, toy_graph.variables[0].prob_dist.prob(None, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_identity(inputs, batch_size, noise_level=0.1):\n",
    "    probs = np.zeros((batch_size, 3))\n",
    "    for val in inputs.values():\n",
    "        val_grid = np.array([noise_level]*3)\n",
    "        val_grid = np.repeat(val_grid[None], batch_size, axis=0)\n",
    "        val_grid[np.arange(batch_size), val] = 1 - noise_level*2\n",
    "        probs += val_grid\n",
    "    probs /= len(inputs)\n",
    "    return probs\n",
    "\n",
    "print(toy_graph.variables[1])\n",
    "toy_graph.variables[1].prob_dist.prob_func = lambda *args, **kwargs: noisy_identity(*args, **kwargs, noise_level=0.25)\n",
    "print(\"---\")\n",
    "for a in range(3):\n",
    "    for i in range(3):\n",
    "        print(\"Prob for val=%i if A=%i: %4.2f\" % (i, a, toy_graph.variables[1].prob_dist.prob({\"A\": a}, i)))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_VARS == 3:\n",
    "    print(toy_graph.variables[2])\n",
    "    toy_graph.variables[2].prob_dist.prob_func = noisy_identity\n",
    "    print(\"---\")\n",
    "    for a in range(3):\n",
    "        for c in range(3):\n",
    "            for i in range(3):\n",
    "                print(\"Prob for val=%i if A=%i,C=%i: %4.2f\" % (i, a, c, toy_graph.variables[2].prob_dist.prob({\"A\":a, \"C\": c}, i)))\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adjacency matrix:\")\n",
    "toy_graph.adj_matrix.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_graph.sample(batch_size=8, as_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discModule = GraphDiscovery(graph=toy_graph, \n",
    "                            model_iters=1000, \n",
    "                            gamma_iters=50, \n",
    "                            dataset_size=10000, \n",
    "                            N_s=10,\n",
    "                            C_s=20,\n",
    "                            lambda_sparse=0.02, \n",
    "                            lambda_DAG=0.1,\n",
    "                            hidden_dims=[64],\n",
    "                            lr_gamma=2e-1,\n",
    "                            betas_gamma=(0.1,-1.0),\n",
    "                            guide_inter=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma = discModule.discover_graph(num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More advanced graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VARS = 4\n",
    "NUM_CATEGS = 5\n",
    "\n",
    "graph = generate_categorical_graph(num_vars=NUM_VARS,\n",
    "                                   min_categs=NUM_CATEGS,\n",
    "                                   max_categs=NUM_CATEGS,\n",
    "                                   edge_prob=0.3,\n",
    "                                   connected=True,\n",
    "                                   inputs_independent=False,\n",
    "                                   use_nn=True, \n",
    "                                   seed=123)\n",
    "visualize_graph(graph, show_plot=True, figsize=(8, 5), layout=\"graphviz\", filename=\"example_graph_8_nodes.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "discModule = GraphDiscovery(graph=graph, \n",
    "                            model_iters=400, \n",
    "                            gamma_iters=50, \n",
    "                            dataset_size=100000, \n",
    "                            lambda_sparse=0.1, \n",
    "                            lambda_DAG=2.0,\n",
    "                            hidden_dims=[64],\n",
    "                            betas_gamma=(0.1, -1.0),\n",
    "                            lr_gamma=2e-2)\n",
    "discModule.print_gamma_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma = discModule.discover_graph(num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_gamma = torch.round(gamma * 100)/100\n",
    "rounded_gamma[torch.arange(gamma.shape[0]), torch.arange(gamma.shape[1])] = 0\n",
    "print(rounded_gamma.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted adjacency matrix\")\n",
    "(gamma>0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True adjacency matrix\")\n",
    "graph.adj_matrix.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted graph\")\n",
    "copied_graph = deepcopy(graph)\n",
    "copied_graph.adj_matrix = (gamma > 0.0).numpy()\n",
    "copied_graph.edges = adj_matrix_to_edges(copied_graph.adj_matrix)\n",
    "visualize_graph(copied_graph, show_plot=True, figsize=(4, 3), layout=\"circular\", filename=\"example_graph_8_nodes_predicted.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discModule.print_gamma_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
