{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Discovery with Plackett-Luce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_discovery import GraphDiscoveryDAG\n",
    "from estimators import to_z, to_b\n",
    "from distributions import PlackettLuce\n",
    "from utils import make_permutation_matrix, combine_order_and_adjmatrix\n",
    "from causal_graphs.graph_generation import generate_categorical_graph, generate_chain, generate_random_graph, VariableGraph\n",
    "from causal_graphs.graph_visualization import visualize_graph\n",
    "from causal_graphs.graph_utils import adj_matrix_to_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VARS = 3\n",
    "NUM_CATEGS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, graph, dataset_size):\n",
    "        super().__init__()\n",
    "        self.graph = graph\n",
    "        self.var_names = [v.name for v in self.graph.variables]\n",
    "        data = graph.sample(batch_size=dataset_size, as_array=True)\n",
    "        self.data = torch.from_numpy(data).long()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1BhZ2VzIDIgMCBSIC9UeXBlIC9DYXRhbG9nID4+CmVuZG9iago4IDAgb2JqCjw8IC9FeHRHU3RhdGUgNCAwIFIgL0ZvbnQgMyAwIFIgL1BhdHRlcm4gNSAwIFIKL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0gL1NoYWRpbmcgNiAwIFIKL1hPYmplY3QgNyAwIFIgPj4KZW5kb2JqCjEwIDAgb2JqCjw8IC9Bbm5vdHMgWyBdIC9Db250ZW50cyA5IDAgUgovR3JvdXAgPDwgL0NTIC9EZXZpY2VSR0IgL1MgL1RyYW5zcGFyZW5jeSAvVHlwZSAvR3JvdXAgPj4KL01lZGlhQm94IFsgMCAwIDIzMC40IDE1OC40IF0gL1BhcmVudCAyIDAgUiAvUmVzb3VyY2VzIDggMCBSIC9UeXBlIC9QYWdlID4+CmVuZG9iago5IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTEgMCBSID4+CnN0cmVhbQp4nK1TTU+UQQy+z6/oUQ92p9+dIytKYuIB3cQfsAK6AQ2SyN+3syywIAcO++adSafTr+eZlmDTFkcEFzdQG3TY1Lot+WSeW6/TVWPpqCVd7iSyrP2ybu+lH62dt2sI5O1iciBV+HMG3+AXLI74LsGnWptatxXsBBbHZ39/rs++nCxhfdMaDcaUTAlIwR6s5pWclLBnN2eg3lHYmARyoIdl1UKB6p0YJNFZPQhIFDWCwmHd2teqcyK7aE0FPVVmdTxQKUy4UrzoednUMHpSSKkNNQd1m+qXgmwpWLZTOBQJCWEFNkxzn4SEYryHRo57DoxAOw4ZmXRPQiaw4GBO1ucc3KEawIyFKIc/MvDE7QFpwePEUTofj7TsBzgUejYcKtmLcXZUkypl9t9OnTAUh/WiHHa6agUXrGrm29zrAqQayHvQc/D1YDQtHGTMtpkWD/Gf+FWvM8ZTW5naFyK8Gn7H5FDrI7tWSftM7F+1i3bdCObwEXCvljSnkaLVoTGQe32ljoD1FSw+dzj+/WD+jiLRiGW4D2WwgdaVpNMcrP/tO85oFCHi5Uyjzsmu6px75qevQfccUjG+XMHiY80Vw+q8mntgps1/C8XqFLaDsvre3izfwmoDH1aHSMaE0qUm2Y3HdoJlkAuz1IvNZEeHTWYS5kPSDchRsviM8PRtrvcPudo/lF8esgplbmRzdHJlYW0KZW5kb2JqCjExIDAgb2JqCjUxOAplbmRvYmoKMTcgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCA4OCA+PgpzdHJlYW0KeJxNjLkNwDAIAHumYASbx8A+USqyfxtMXKQATuJ0ZoIDtcZWoFHgNUFZcDLjAySjKWHGFhO0N5m2nCARh3agDR/fPZWy3ZCWV08OJXCRqv++CfcLiwobfwplbmRzdHJlYW0KZW5kb2JqCjE4IDAgb2JqCjw8IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMjY4ID4+CnN0cmVhbQp4nEWRy3EEMQhE74qCEMRXIp51+TSb/9XdrMs+jOjSoOYBp0y2NI/CeazlS5ffkIgj7xXqo8JTIqFTJarktXjGaXzI7TsxLfiHKnrysu68yav8A5ds5MO1tgrrML6W3T3qGcWKzx8FVG9Ru+TBSRVZok6CFE2jN3wV1XIjohVGG55RCX5k2BCnWCffwMUVHcHRtYV1GD88VB8eVvyneFZWTu571YY6Vwosnkcq4WT0Lryz9hkrq0/c9KZSbynQ3pKyLdNBHtwfgG9sIwC9cTmredbvbgCB4X4U26DKuHIwUA62rrMAzWFZWG5tn5jOpY2Cf3GVB9Gx2hhcUARJGkPdyPpt8bW+fwCet2c7CmVuZHN0cmVhbQplbmRvYmoKMTkgMCBvYmoKPDwgL0ZpbHRlciAvRmxhdGVEZWNvZGUgL0xlbmd0aCAyMzAgPj4Kc3RyZWFtCnicLVDLbUMxDLt7Ci4QwPrb86TIKd3/WlGvJxIWJZIuc2zExksMWRvlih9ZpL7xu9ICqoh7cRCprX6vUMfrwE/MnvuD72Vqw1QLuiGROKffWygR9FEvgqXzTpucjZ5G6ajTeZ/rtQ94joFoQHwvWpIxQVlNolJaMGHJBQPXzimTY04Wrf1OmUhBbmlH9ukL53Lbuv7uOLcaE557sCtdHWZ2W+sw7rowZXb1e7qSw3tKfHqRaXtToXpnR85ca524gVel/5U+xG7WzmRMIlqTTWzyc9ufZtKv7CNX/pv1h33X5w91SFT8CmVuZHN0cmVhbQplbmRvYmoKMTUgMCBvYmoKPDwgL0Jhc2VGb250IC9EZWphVnVTYW5zLUJvbGQgL0NoYXJQcm9jcyAxNiAwIFIKL0VuY29kaW5nIDw8IC9EaWZmZXJlbmNlcyBbIDY1IC9BIC9CIC9DIF0gL1R5cGUgL0VuY29kaW5nID4+IC9GaXJzdENoYXIgMAovRm9udEJCb3ggWyAtMTA3MCAtNDE2IDE5NzYgMTE3NSBdIC9Gb250RGVzY3JpcHRvciAxNCAwIFIKL0ZvbnRNYXRyaXggWyAwLjAwMSAwIDAgMC4wMDEgMCAwIF0gL0xhc3RDaGFyIDI1NSAvTmFtZSAvRGVqYVZ1U2Fucy1Cb2xkCi9TdWJ0eXBlIC9UeXBlMyAvVHlwZSAvRm9udCAvV2lkdGhzIDEzIDAgUiA+PgplbmRvYmoKMTQgMCBvYmoKPDwgL0FzY2VudCA5MjkgL0NhcEhlaWdodCAwIC9EZXNjZW50IC0yMzYgL0ZsYWdzIDMyCi9Gb250QkJveCBbIC0xMDcwIC00MTYgMTk3NiAxMTc1IF0gL0ZvbnROYW1lIC9EZWphVnVTYW5zLUJvbGQKL0l0YWxpY0FuZ2xlIDAgL01heFdpZHRoIDE0NDAgL1N0ZW1WIDAgL1R5cGUgL0ZvbnREZXNjcmlwdG9yIC9YSGVpZ2h0IDAgPj4KZW5kb2JqCjEzIDAgb2JqClsgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAKNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCAzNDggNDU2IDUyMSA4MzggNjk2CjEwMDIgODcyIDMwNiA0NTcgNDU3IDUyMyA4MzggMzgwIDQxNSAzODAgMzY1IDY5NiA2OTYgNjk2IDY5NiA2OTYgNjk2IDY5Ngo2OTYgNjk2IDY5NiA0MDAgNDAwIDgzOCA4MzggODM4IDU4MCAxMDAwIDc3NCA3NjIgNzM0IDgzMCA2ODMgNjgzIDgyMSA4MzcKMzcyIDM3MiA3NzUgNjM3IDk5NSA4MzcgODUwIDczMyA4NTAgNzcwIDcyMCA2ODIgODEyIDc3NCAxMTAzIDc3MSA3MjQgNzI1CjQ1NyAzNjUgNDU3IDgzOCA1MDAgNTAwIDY3NSA3MTYgNTkzIDcxNiA2NzggNDM1IDcxNiA3MTIgMzQzIDM0MyA2NjUgMzQzCjEwNDIgNzEyIDY4NyA3MTYgNzE2IDQ5MyA1OTUgNDc4IDcxMiA2NTIgOTI0IDY0NSA2NTIgNTgyIDcxMiAzNjUgNzEyIDgzOAo2MDAgNjk2IDYwMCAzODAgNDM1IDY1NyAxMDAwIDUwMCA1MDAgNTAwIDE0NDAgNzIwIDQxMiAxMTY3IDYwMCA3MjUgNjAwIDYwMAozODAgMzgwIDY1NyA2NTcgNjM5IDUwMCAxMDAwIDUwMCAxMDAwIDU5NSA0MTIgMTA5NCA2MDAgNTgyIDcyNCAzNDggNDU2IDY5Ngo2OTYgNjM2IDY5NiAzNjUgNTAwIDUwMCAxMDAwIDU2NCA2NDYgODM4IDQxNSAxMDAwIDUwMCA1MDAgODM4IDQzOCA0MzggNTAwCjczNiA2MzYgMzgwIDUwMCA0MzggNTY0IDY0NiAxMDM1IDEwMzUgMTAzNSA1ODAgNzc0IDc3NCA3NzQgNzc0IDc3NCA3NzQgMTA4NQo3MzQgNjgzIDY4MyA2ODMgNjgzIDM3MiAzNzIgMzcyIDM3MiA4MzggODM3IDg1MCA4NTAgODUwIDg1MCA4NTAgODM4IDg1MCA4MTIKODEyIDgxMiA4MTIgNzI0IDczOCA3MTkgNjc1IDY3NSA2NzUgNjc1IDY3NSA2NzUgMTA0OCA1OTMgNjc4IDY3OCA2NzggNjc4CjM0MyAzNDMgMzQzIDM0MyA2ODcgNzEyIDY4NyA2ODcgNjg3IDY4NyA2ODcgODM4IDY4NyA3MTIgNzEyIDcxMiA3MTIgNjUyIDcxNgo2NTIgXQplbmRvYmoKMTYgMCBvYmoKPDwgL0EgMTcgMCBSIC9CIDE4IDAgUiAvQyAxOSAwIFIgPj4KZW5kb2JqCjMgMCBvYmoKPDwgL0YxIDE1IDAgUiA+PgplbmRvYmoKNCAwIG9iago8PCAvQTEgPDwgL0NBIDAgL1R5cGUgL0V4dEdTdGF0ZSAvY2EgMSA+PgovQTIgPDwgL0NBIDEgL1R5cGUgL0V4dEdTdGF0ZSAvY2EgMSA+PiA+PgplbmRvYmoKNSAwIG9iago8PCA+PgplbmRvYmoKNiAwIG9iago8PCA+PgplbmRvYmoKNyAwIG9iago8PCAvTTAgMTIgMCBSID4+CmVuZG9iagoxMiAwIG9iago8PCAvQkJveCBbIC0xNy4yNDc0NDg3MTM5IC0xNy4yNDc0NDg3MTM5IDE3LjI0NzQ0ODcxMzkgMTcuMjQ3NDQ4NzEzOSBdCi9GaWx0ZXIgL0ZsYXRlRGVjb2RlIC9MZW5ndGggMTM5IC9TdWJ0eXBlIC9Gb3JtIC9UeXBlIC9YT2JqZWN0ID4+CnN0cmVhbQp4nG1QOw5DMQjbOQUXcER+NFk7vmu8parU+69NhwepHktEDNjGmd8kfNB6kEsq7dHa5A/VVQ7RvKOaqtZexsIkza5z8EiqUnpjWHWSdWEbTgJjdkx+S/bzgYvHaExkU3ONazxU8PqkyAPuPIjkcHeFwDv+r0MUAIKgECaKIHrEWtgPfRE96QuL9FyJCmVuZHN0cmVhbQplbmRvYmoKMiAwIG9iago8PCAvQ291bnQgMSAvS2lkcyBbIDEwIDAgUiBdIC9UeXBlIC9QYWdlcyA+PgplbmRvYmoKMjAgMCBvYmoKPDwgL0NyZWF0aW9uRGF0ZSAoRDoyMDIxMDMwMjEwNTEyNyswMicwMCcpCi9DcmVhdG9yIChNYXRwbG90bGliIHYzLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZykKL1Byb2R1Y2VyIChNYXRwbG90bGliIHBkZiBiYWNrZW5kIHYzLjMuMykgPj4KZW5kb2JqCnhyZWYKMCAyMQowMDAwMDAwMDAwIDY1NTM1IGYgCjAwMDAwMDAwMTYgMDAwMDAgbiAKMDAwMDAwMzk1NCAwMDAwMCBuIAowMDAwMDAzNDM5IDAwMDAwIG4gCjAwMDAwMDM0NzEgMDAwMDAgbiAKMDAwMDAwMzU3MCAwMDAwMCBuIAowMDAwMDAzNTkxIDAwMDAwIG4gCjAwMDAwMDM2MTIgMDAwMDAgbiAKMDAwMDAwMDA2NSAwMDAwMCBuIAowMDAwMDAwMzg5IDAwMDAwIG4gCjAwMDAwMDAyMDggMDAwMDAgbiAKMDAwMDAwMDk4MiAwMDAwMCBuIAowMDAwMDAzNjQ0IDAwMDAwIG4gCjAwMDAwMDIzMjYgMDAwMDAgbiAKMDAwMDAwMjEyMSAwMDAwMCBuIAowMDAwMDAxODA2IDAwMDAwIG4gCjAwMDAwMDMzODcgMDAwMDAgbiAKMDAwMDAwMTAwMiAwMDAwMCBuIAowMDAwMDAxMTYyIDAwMDAwIG4gCjAwMDAwMDE1MDMgMDAwMDAgbiAKMDAwMDAwNDAxNCAwMDAwMCBuIAp0cmFpbGVyCjw8IC9JbmZvIDIwIDAgUiAvUm9vdCAxIDAgUiAvU2l6ZSAyMSA+PgpzdGFydHhyZWYKNDE3MQolJUVPRgo=\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"158.4pt\" version=\"1.1\" viewBox=\"0 0 230.4 158.4\" width=\"230.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-03-02T10:51:27.064418</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 158.4 \n",
       "L 230.4 158.4 \n",
       "L 230.4 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 192.838837 75.327544 \n",
       "Q 115.201424 49.448408 38.624671 23.922824 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 43.684316 28.982468 \n",
       "L 38.624671 23.922824 \n",
       "L 45.708173 22.910895 \n",
       "L 43.684316 28.982468 \n",
       "z\n",
       "\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 192.838838 83.072452 \n",
       "Q 115.201433 108.95159 38.624688 134.477176 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 45.70819 135.489104 \n",
       "L 38.624688 134.477176 \n",
       "L 43.684332 129.417531 \n",
       "L 45.70819 135.489104 \n",
       "z\n",
       "\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 25.943803 31.946078 \n",
       "Q 25.943811 79.201699 25.943817 125.339286 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n",
       "    <path clip-path=\"url(#p94993b431e)\" d=\"M 29.143816 118.939286 \n",
       "L 25.943817 125.339286 \n",
       "L 22.743816 118.939287 \n",
       "L 29.143816 118.939286 \n",
       "z\n",
       "\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 12.247449 \n",
       "C 3.248061 12.247449 6.363528 10.95698 8.660254 8.660254 \n",
       "C 10.95698 6.363528 12.247449 3.248061 12.247449 0 \n",
       "C 12.247449 -3.248061 10.95698 -6.363528 8.660254 -8.660254 \n",
       "C 6.363528 -10.95698 3.248061 -12.247449 0 -12.247449 \n",
       "C -3.248061 -12.247449 -6.363528 -10.95698 -8.660254 -8.660254 \n",
       "C -10.95698 -6.363528 -12.247449 -3.248061 -12.247449 0 \n",
       "C -12.247449 3.248061 -10.95698 6.363528 -8.660254 8.660254 \n",
       "C -6.363528 10.95698 -3.248061 12.247449 0 12.247449 \n",
       "z\n",
       "\" id=\"mae4dd39164\" style=\"stroke:#000000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p94993b431e)\">\n",
       "     <use style=\"fill:#d3d3d3;stroke:#000000;\" x=\"204.456198\" xlink:href=\"#mae4dd39164\" y=\"79.199998\"/>\n",
       "     <use style=\"fill:#d3d3d3;stroke:#000000;\" x=\"25.943802\" xlink:href=\"#mae4dd39164\" y=\"19.695868\"/>\n",
       "     <use style=\"fill:#d3d3d3;stroke:#000000;\" x=\"25.943819\" xlink:href=\"#mae4dd39164\" y=\"138.704132\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <g clip-path=\"url(#p94993b431e)\">\n",
       "     <!-- B -->\n",
       "     <g transform=\"translate(199.883073 82.511248)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 38.375 44.671875 \n",
       "Q 42.828125 44.671875 45.109375 46.625 \n",
       "Q 47.40625 48.578125 47.40625 52.390625 \n",
       "Q 47.40625 56.15625 45.109375 58.125 \n",
       "Q 42.828125 60.109375 38.375 60.109375 \n",
       "L 27.984375 60.109375 \n",
       "L 27.984375 44.671875 \n",
       "z\n",
       "M 39.015625 12.796875 \n",
       "Q 44.671875 12.796875 47.53125 15.1875 \n",
       "Q 50.390625 17.578125 50.390625 22.40625 \n",
       "Q 50.390625 27.15625 47.5625 29.515625 \n",
       "Q 44.734375 31.890625 39.015625 31.890625 \n",
       "L 27.984375 31.890625 \n",
       "L 27.984375 12.796875 \n",
       "z\n",
       "M 56.5 39.015625 \n",
       "Q 62.546875 37.25 65.859375 32.515625 \n",
       "Q 69.1875 27.78125 69.1875 20.90625 \n",
       "Q 69.1875 10.359375 62.0625 5.171875 \n",
       "Q 54.9375 0 40.375 0 \n",
       "L 9.1875 0 \n",
       "L 9.1875 72.90625 \n",
       "L 37.40625 72.90625 \n",
       "Q 52.59375 72.90625 59.40625 68.3125 \n",
       "Q 66.21875 63.71875 66.21875 53.609375 \n",
       "Q 66.21875 48.296875 63.71875 44.5625 \n",
       "Q 61.234375 40.828125 56.5 39.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-Bold-66\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Bold-66\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <g clip-path=\"url(#p94993b431e)\">\n",
       "     <!-- A -->\n",
       "     <g transform=\"translate(21.300364 23.007118)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 53.421875 13.28125 \n",
       "L 24.03125 13.28125 \n",
       "L 19.390625 0 \n",
       "L 0.484375 0 \n",
       "L 27.484375 72.90625 \n",
       "L 49.90625 72.90625 \n",
       "L 76.90625 0 \n",
       "L 58.015625 0 \n",
       "z\n",
       "M 28.71875 26.8125 \n",
       "L 48.6875 26.8125 \n",
       "L 38.71875 55.8125 \n",
       "z\n",
       "\" id=\"DejaVuSans-Bold-65\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Bold-65\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <g clip-path=\"url(#p94993b431e)\">\n",
       "     <!-- C -->\n",
       "     <g transform=\"translate(21.540382 142.015382)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 67 4 \n",
       "Q 61.8125 1.3125 56.203125 -0.046875 \n",
       "Q 50.59375 -1.421875 44.484375 -1.421875 \n",
       "Q 26.265625 -1.421875 15.625 8.765625 \n",
       "Q 4.984375 18.953125 4.984375 36.375 \n",
       "Q 4.984375 53.859375 15.625 64.03125 \n",
       "Q 26.265625 74.21875 44.484375 74.21875 \n",
       "Q 50.59375 74.21875 56.203125 72.84375 \n",
       "Q 61.8125 71.484375 67 68.796875 \n",
       "L 67 53.71875 \n",
       "Q 61.765625 57.28125 56.6875 58.9375 \n",
       "Q 51.609375 60.59375 46 60.59375 \n",
       "Q 35.9375 60.59375 30.171875 54.140625 \n",
       "Q 24.421875 47.703125 24.421875 36.375 \n",
       "Q 24.421875 25.09375 30.171875 18.640625 \n",
       "Q 35.9375 12.203125 46 12.203125 \n",
       "Q 51.609375 12.203125 56.6875 13.859375 \n",
       "Q 61.765625 15.53125 67 19.09375 \n",
       "z\n",
       "\" id=\"DejaVuSans-Bold-67\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Bold-67\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p94993b431e\">\n",
       "   <rect height=\"144\" width=\"216\" x=\"7.2\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 216x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = generate_categorical_graph(num_vars=NUM_VARS,\n",
    "                                   min_categs=NUM_CATEGS,\n",
    "                                   max_categs=NUM_CATEGS,\n",
    "                                   edge_prob=1.0,\n",
    "                                   connected=True,\n",
    "                                   seed=42)\n",
    "visualize_graph(graph, show_plot=True, figsize=(3, 2), layout=\"circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CategoricalData(graph, dataset_size=64*128)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing discovery methods\n",
    "\n",
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z tensor([0.3367, 0.1288, 0.2345, 0.2303])\n",
      "b tensor([0, 2, 3, 1])\n",
      "P tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn(4)\n",
    "b = to_b(z)\n",
    "P = make_permutation_matrix(b)\n",
    "\n",
    "print(\"z\", z)\n",
    "print(\"b\", b)\n",
    "print(\"P\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]])\n",
      "Order tensor([3, 0, 2, 1])\n",
      "Combined A tensor([[ 0.,  2.,  3.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.],\n",
      "        [ 0., 10.,  0.,  0.],\n",
      "        [13., 14., 15.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(16).reshape(4, 4) + 1\n",
    "order = torch.LongTensor([3, 0, 2, 1])\n",
    "\n",
    "print(\"A\", A)\n",
    "print(\"Order\", order)\n",
    "print(\"Combined A\", combine_order_and_adjmatrix(A, order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired result:\n",
    "\n",
    "$$\\hat{A}=\\begin{bmatrix}0 & 2 & 3 & 0\\\\0 & 0 & 0 & 0\\\\ 0 & 10 & 0 & 0\\\\ 13 & 14 & 15 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-9.0000e+15,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.0000e+15,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.0000e+15]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "discovery_module = GraphDiscoveryDAG(graph=graph, model_iters=1000, lambda_sparse=0.001, batch_size=128)\n",
    "print(discovery_module.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [1., 0., 1.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "s = discovery_module.sample_func(sample_matrix=torch.sigmoid(discovery_module.gamma), batch_size=4)\n",
    "assert (s[:,torch.arange(s.shape[1]),torch.arange(s.shape[2])] == 0).all(), \"All diagonal elements have to be 0!\"\n",
    "assert ((s * s.transpose(-1,-2)) == 0).all(), \"No two-way connections are allowed\"\n",
    "assert (s.sum(dim=2) == 0).any(dim=1).all(), \"At least one node needs to be a leaf-node\"\n",
    "assert (s.sum(dim=1) == 0).any(dim=1).all(), \"At least one node needs to be a head-node\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_orders(var_list, s_list=None):\n",
    "    if s_list is None:\n",
    "        s_list = []\n",
    "    if isinstance(var_list, int):\n",
    "        var_list = [i for i in range(var_list)]\n",
    "    \n",
    "    for i in var_list:\n",
    "        sub_var_list = [j for j in var_list if i != j]\n",
    "        if len(sub_var_list) == 0:\n",
    "            s_list.append([i])\n",
    "        else:\n",
    "            sub_var_list = get_all_orders(var_list=sub_var_list)\n",
    "            for l in sub_var_list:\n",
    "                s_list.append([i] + l)\n",
    "    return s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3],\n",
       " [0, 1, 3, 2],\n",
       " [0, 2, 1, 3],\n",
       " [0, 2, 3, 1],\n",
       " [0, 3, 1, 2],\n",
       " [0, 3, 2, 1],\n",
       " [1, 0, 2, 3],\n",
       " [1, 0, 3, 2],\n",
       " [1, 2, 0, 3],\n",
       " [1, 2, 3, 0],\n",
       " [1, 3, 0, 2],\n",
       " [1, 3, 2, 0],\n",
       " [2, 0, 1, 3],\n",
       " [2, 0, 3, 1],\n",
       " [2, 1, 0, 3],\n",
       " [2, 1, 3, 0],\n",
       " [2, 3, 0, 1],\n",
       " [2, 3, 1, 0],\n",
       " [3, 0, 1, 2],\n",
       " [3, 0, 2, 1],\n",
       " [3, 1, 0, 2],\n",
       " [3, 1, 2, 0],\n",
       " [3, 2, 0, 1],\n",
       " [3, 2, 1, 0]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_orders(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_samples = torch.LongTensor(get_all_orders(5))\n",
    "theta_grads, debug = discovery_module.updateModule.order_gradient_estimator(logregret=torch.zeros(order_samples.shape),\n",
    "                                                                            order_samples=order_samples,\n",
    "                                                                            pl_thetas=torch.zeros(order_samples.shape[-1]),\n",
    "                                                                            var_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 4, 3],\n",
       "        [0, 1, 3, 2, 4],\n",
       "        [0, 1, 3, 4, 2],\n",
       "        [0, 1, 4, 2, 3],\n",
       "        [0, 1, 4, 3, 2],\n",
       "        [0, 2, 1, 3, 4],\n",
       "        [0, 2, 1, 4, 3],\n",
       "        [0, 2, 3, 1, 4],\n",
       "        [0, 2, 3, 4, 1],\n",
       "        [0, 2, 4, 1, 3],\n",
       "        [0, 2, 4, 3, 1],\n",
       "        [0, 3, 1, 2, 4],\n",
       "        [0, 3, 1, 4, 2],\n",
       "        [0, 3, 2, 1, 4],\n",
       "        [0, 3, 2, 4, 1],\n",
       "        [0, 3, 4, 1, 2],\n",
       "        [0, 3, 4, 2, 1],\n",
       "        [0, 4, 1, 2, 3],\n",
       "        [0, 4, 1, 3, 2],\n",
       "        [0, 4, 2, 1, 3],\n",
       "        [0, 4, 2, 3, 1],\n",
       "        [0, 4, 3, 1, 2],\n",
       "        [0, 4, 3, 2, 1],\n",
       "        [1, 0, 2, 3, 4],\n",
       "        [1, 0, 2, 4, 3],\n",
       "        [1, 0, 3, 2, 4],\n",
       "        [1, 0, 3, 4, 2],\n",
       "        [1, 0, 4, 2, 3],\n",
       "        [1, 0, 4, 3, 2],\n",
       "        [1, 2, 0, 3, 4],\n",
       "        [1, 2, 0, 4, 3],\n",
       "        [1, 2, 3, 0, 4],\n",
       "        [1, 2, 3, 4, 0],\n",
       "        [1, 2, 4, 0, 3],\n",
       "        [1, 2, 4, 3, 0],\n",
       "        [1, 3, 0, 2, 4],\n",
       "        [1, 3, 0, 4, 2],\n",
       "        [1, 3, 2, 0, 4],\n",
       "        [1, 3, 2, 4, 0],\n",
       "        [1, 3, 4, 0, 2],\n",
       "        [1, 3, 4, 2, 0],\n",
       "        [1, 4, 0, 2, 3],\n",
       "        [1, 4, 0, 3, 2],\n",
       "        [1, 4, 2, 0, 3],\n",
       "        [1, 4, 2, 3, 0],\n",
       "        [1, 4, 3, 0, 2],\n",
       "        [1, 4, 3, 2, 0],\n",
       "        [2, 0, 1, 3, 4],\n",
       "        [2, 0, 1, 4, 3],\n",
       "        [2, 0, 3, 1, 4],\n",
       "        [2, 0, 3, 4, 1],\n",
       "        [2, 0, 4, 1, 3],\n",
       "        [2, 0, 4, 3, 1],\n",
       "        [2, 1, 0, 3, 4],\n",
       "        [2, 1, 0, 4, 3],\n",
       "        [2, 1, 3, 0, 4],\n",
       "        [2, 1, 3, 4, 0],\n",
       "        [2, 1, 4, 0, 3],\n",
       "        [2, 1, 4, 3, 0],\n",
       "        [2, 3, 0, 1, 4],\n",
       "        [2, 3, 0, 4, 1],\n",
       "        [2, 3, 1, 0, 4],\n",
       "        [2, 3, 1, 4, 0],\n",
       "        [2, 3, 4, 0, 1],\n",
       "        [2, 3, 4, 1, 0],\n",
       "        [2, 4, 0, 1, 3],\n",
       "        [2, 4, 0, 3, 1],\n",
       "        [2, 4, 1, 0, 3],\n",
       "        [2, 4, 1, 3, 0],\n",
       "        [2, 4, 3, 0, 1],\n",
       "        [2, 4, 3, 1, 0],\n",
       "        [3, 0, 1, 2, 4],\n",
       "        [3, 0, 1, 4, 2],\n",
       "        [3, 0, 2, 1, 4],\n",
       "        [3, 0, 2, 4, 1],\n",
       "        [3, 0, 4, 1, 2],\n",
       "        [3, 0, 4, 2, 1],\n",
       "        [3, 1, 0, 2, 4],\n",
       "        [3, 1, 0, 4, 2],\n",
       "        [3, 1, 2, 0, 4],\n",
       "        [3, 1, 2, 4, 0],\n",
       "        [3, 1, 4, 0, 2],\n",
       "        [3, 1, 4, 2, 0],\n",
       "        [3, 2, 0, 1, 4],\n",
       "        [3, 2, 0, 4, 1],\n",
       "        [3, 2, 1, 0, 4],\n",
       "        [3, 2, 1, 4, 0],\n",
       "        [3, 2, 4, 0, 1],\n",
       "        [3, 2, 4, 1, 0],\n",
       "        [3, 4, 0, 1, 2],\n",
       "        [3, 4, 0, 2, 1],\n",
       "        [3, 4, 1, 0, 2],\n",
       "        [3, 4, 1, 2, 0],\n",
       "        [3, 4, 2, 0, 1],\n",
       "        [3, 4, 2, 1, 0],\n",
       "        [4, 0, 1, 2, 3],\n",
       "        [4, 0, 1, 3, 2],\n",
       "        [4, 0, 2, 1, 3],\n",
       "        [4, 0, 2, 3, 1],\n",
       "        [4, 0, 3, 1, 2],\n",
       "        [4, 0, 3, 2, 1],\n",
       "        [4, 1, 0, 2, 3],\n",
       "        [4, 1, 0, 3, 2],\n",
       "        [4, 1, 2, 0, 3],\n",
       "        [4, 1, 2, 3, 0],\n",
       "        [4, 1, 3, 0, 2],\n",
       "        [4, 1, 3, 2, 0],\n",
       "        [4, 2, 0, 1, 3],\n",
       "        [4, 2, 0, 3, 1],\n",
       "        [4, 2, 1, 0, 3],\n",
       "        [4, 2, 1, 3, 0],\n",
       "        [4, 2, 3, 0, 1],\n",
       "        [4, 2, 3, 1, 0],\n",
       "        [4, 3, 0, 1, 2],\n",
       "        [4, 3, 0, 2, 1],\n",
       "        [4, 3, 1, 0, 2],\n",
       "        [4, 3, 1, 2, 0],\n",
       "        [4, 3, 2, 0, 1],\n",
       "        [4, 3, 2, 1, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 1., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 0.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug[\"comp_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug[\"graph_weight_red\"][:,1:2,2:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2250, 0.4500, 0.5484, 0.5484],\n",
       "        [0.8719, 0.0000, 1.0969, 0.8719, 0.8719],\n",
       "        [0.6469, 0.0000, 0.0000, 0.6469, 0.6469],\n",
       "        [0.5484, 0.2250, 0.4500, 0.0000, 0.5484],\n",
       "        [0.5484, 0.2250, 0.4500, 0.5484, 0.0000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(debug[\"comp_matrix\"] * debug[\"graph_weight_red\"][:,1:2,2:3])[torch.where(debug[\"comp_matrix\"][:,1,2] == 1.0)].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4500, 0.2250, 0.5484, 0.5484],\n",
       "        [0.6469, 0.0000, 0.0000, 0.6469, 0.6469],\n",
       "        [0.8719, 1.0969, 0.0000, 0.8719, 0.8719],\n",
       "        [0.5484, 0.4500, 0.2250, 0.0000, 0.5484],\n",
       "        [0.5484, 0.4500, 0.2250, 0.5484, 0.0000]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(debug[\"comp_matrix\"] * debug[\"graph_weight_red\"][:,2:3,1:2])[torch.where(debug[\"comp_matrix\"][:,2,1] == 1.0)].mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that any edge to or from $B$ must be with 50 chance, others are irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_gamma = torch.from_numpy(graph.adj_matrix).float()\n",
    "true_gamma = true_gamma + true_gamma.T\n",
    "true_gamma.masked_fill_(true_gamma == 0, -9e15)\n",
    "true_gamma.masked_fill_(true_gamma == 1, 9e15)\n",
    "discovery_module.gamma.data = true_gamma.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Model update loop', max=1000.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discovery_module.model_fitting_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention on variable B\n",
      "Theta grads tensor([0.0000, 0.0238, 0.0184])\n",
      "Theta grads tensor([0.0000, 0.0038, 0.0366])\n",
      "Theta grads tensor([0.0000, 0.0756, 0.0052])\n",
      "Theta grads tensor([ 0.0000,  0.0683, -0.0102])\n",
      "Intervention on variable A\n",
      "Theta grads tensor([-0.1648,  0.0000,  0.0206])\n",
      "Theta grads tensor([-0.0393,  0.0000,  0.0159])\n",
      "Theta grads tensor([ 0.0182,  0.0000, -0.0311])\n",
      "Theta grads tensor([-0.3872,  0.0000, -0.0068])\n",
      "Intervention on variable C\n",
      "Theta grads tensor([-0.0256,  0.0669,  0.0000])\n",
      "Theta grads tensor([-0.0264,  0.0574,  0.0000])\n",
      "Theta grads tensor([ 0.0298, -0.0166,  0.0000])\n",
      "Theta grads tensor([0.0027, 0.0020, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "discovery_module.scoringModule.N_s = 1 \n",
    "discovery_module.scoringModule.C_s = 200\n",
    "# discovery_module.scoringModule.batch_size = 2048\n",
    "debug_dicts = {}\n",
    "pl.seed_everything(40)\n",
    "for idx in range(graph.num_vars):\n",
    "    print(\"Intervention on variable\", graph.variables[idx].name)\n",
    "    debug_dicts[idx] = list()\n",
    "    for _ in range(4):\n",
    "        gammagrad, logregret, gammamask, theta_z, theta_b, var_idx, debug_score = discovery_module.scoringModule.score(discovery_module.gamma, discovery_module.pl_thetas, var_idx=idx, return_debug=True)\n",
    "        theta_grads, debug = discovery_module.updateModule.order_gradient_estimator(logregret, theta_b, discovery_module.pl_thetas, var_idx)\n",
    "        debug[\"gammamask\"] = gammamask\n",
    "        debug[\"scoring\"] = debug_score\n",
    "        debug_dicts[idx].append(debug)\n",
    "        print(\"Theta grads\", theta_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"order_samples\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"comp_matrix\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 0.7500],\n",
       "         [1.0000, 1.5000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 0.7500],\n",
       "         [1.0000, 1.0000, 1.0000],\n",
       "         [1.5000, 1.0000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.7500, 1.0000],\n",
       "         [0.7500, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"graph_weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7500, 1.5000],\n",
       "        [0.7500, 1.0000, 1.5000],\n",
       "        [0.7500, 0.7500, 1.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"graph_weight_red\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.]],\n",
       "\n",
       "         [[0., 0., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"eye_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500]],\n",
       "\n",
       "        [[0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500]],\n",
       "\n",
       "        [[0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500],\n",
       "         [0.7500, 0.7500, 0.7500]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"factor_A_B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000]],\n",
       "\n",
       "        [[1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000]],\n",
       "\n",
       "        [[1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000],\n",
       "         [1.5000, 1.5000, 1.5000]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"factor_neg_A_B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667]],\n",
       "\n",
       "        [[0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667]],\n",
       "\n",
       "        [[0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667],\n",
       "         [0.6667, 0.6667, 0.6667]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"p_A_C_gA_B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5000, 1.5000, 1.5000],\n",
       "         [0.7500, 1.5000, 0.7500],\n",
       "         [0.7500, 1.5000, 1.5000]],\n",
       "\n",
       "        [[1.5000, 1.5000, 1.5000],\n",
       "         [0.7500, 1.5000, 0.7500],\n",
       "         [0.7500, 1.5000, 1.5000]],\n",
       "\n",
       "        [[1.5000, 1.5000, 1.5000],\n",
       "         [0.7500, 1.5000, 0.7500],\n",
       "         [0.7500, 1.5000, 1.5000]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"factor_comb_A_B\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7500, 0.7500, 0.7500],\n",
       "         [1.5000, 0.7500, 1.5000],\n",
       "         [1.5000, 0.7500, 0.7500]],\n",
       "\n",
       "        [[0.7500, 0.7500, 0.7500],\n",
       "         [1.5000, 0.7500, 1.5000],\n",
       "         [1.5000, 0.7500, 0.7500]],\n",
       "\n",
       "        [[0.7500, 0.7500, 0.7500],\n",
       "         [1.5000, 0.7500, 1.5000],\n",
       "         [1.5000, 0.7500, 0.7500]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"factor_comb_B_A\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][0][\"factor_comb_B_A\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4902, 0.4975],\n",
       "        [0.7574, 0.0000, 1.0025],\n",
       "        [0.2525, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(debug_dicts[0][0][\"comp_matrix\"] * debug_dicts[0][0][\"graph_weight_red\"])[torch.where(debug_dicts[0][0][\"comp_matrix\"][:,1,2] == 1.0)].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3268, 0.6634],\n",
       "        [0.6732, 0.0000, 1.0000],\n",
       "        [0.3366, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(debug_dicts[0][0][\"comp_matrix\"])[torch.where(debug_dicts[0][0][\"comp_matrix\"][:,1,2] == 1.0)].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  0.0130,  0.0035],\n",
       "        [-0.0130,  0.5000, -0.0095],\n",
       "        [-0.0035,  0.0095,  0.5000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_dicts[0][0][\"comp_grads\"].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][3][\"logregret\"][5,0,-1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(debug_dicts[0][3][\"logregret\"][:,0,-1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][3][\"comp_matrix\"][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][3][\"gammamask\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][3][\"pairgrads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[0][3][\"pairgrads\"].sum(dim=1)[1:] - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- debug_dicts[0][3][\"pairgrads\"].sum(dim=0)[1:] + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(40)\n",
    "batch = torch.randint(NUM_CATEGS, size=(16, NUM_VARS))\n",
    "batch[:,2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = discovery_module.scoringModule.evaluate_likelihoods(batch, debug_dicts[1][3][\"gammamask\"][0:1].expand(batch.shape[0],-1,-1), var_idx=0)\n",
    "print(nll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dicts[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammagrad, logregret, gammamask, theta_z, theta_b, var_idx = discovery_module.scoringModule.score(discovery_module.gamma, discovery_module.pl_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammamask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discovery_module.updateModule.update(gammagrad, logregret, gammamask, discovery_module.gamma, var_idx,\n",
    "                                     theta_z, theta_b, discovery_module.pl_thetas, discovery_module.pl_critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "discovery_module.discover_graph(num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_module.get_binary_adjmatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(torch.sigmoid(discovery_module.gamma) * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_module.get_binary_adjmatrix() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_module.pl_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_module.pl_thetas.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_graph(adj_matrix):\n",
    "    copy_graph = deepcopy(discovery_module.scoringModule.graph)\n",
    "    copy_graph.adj_matrix = discovery_module.get_binary_adjmatrix().detach().cpu().numpy()\n",
    "    copy_graph.edges = adj_matrix_to_edges(copy_graph.adj_matrix)\n",
    "    visualize_graph(copy_graph, \n",
    "                    show_plot=True,\n",
    "                    figsize=(4, 4), \n",
    "                    layout=\"circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_graph(discovery_module.get_binary_adjmatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammagrad, logregret, gammamask, theta_z, theta_b, var_idx = discovery_module.scoringModule.score(discovery_module.gamma, discovery_module.pl_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_grads, debug = discovery_module.updateModule.order_gradient_estimator(logregret, theta_b, discovery_module.pl_thetas, var_idx)\n",
    "pairgrads = debug[\"pairgrads\"]\n",
    "print(\"Theta grads\\n\" + str(theta_grads))\n",
    "print(\"\\nPair grads\\n\" + str(pairgrads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairgrads.sum(dim=1) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairgrads.sum(dim=0) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"logregret\"].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(debug[\"logregret\"].squeeze()[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"comp_matrix\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"comp_matrix\"][:,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"logregret\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_regret = (debug[\"comp_matrix\"] * debug[\"logregret\"]).sum(dim=0) / debug[\"comp_matrix\"].sum(dim=0)\n",
    "print(\"Positive regret\")\n",
    "print(pos_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_regret = ((1-debug[\"comp_matrix\"]) * debug[\"logregret\"]).sum(dim=0) / (1-debug[\"comp_matrix\"]).sum(dim=0)\n",
    "print(\"Negative regret\")\n",
    "print(neg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"logregret\"][torch.where(debug[\"comp_matrix\"][:,2,1] == 0)[0],0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_b[torch.where(debug[\"comp_matrix\"][:,2,1] == 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = PlackettLuce(discovery_module.pl_thetas)\n",
    "order_samples = torch.LongTensor([[0, 1, 2],\n",
    "                                  [0, 2, 1],\n",
    "                                  [1, 2, 0],\n",
    "                                  [1, 0, 2],\n",
    "                                  [2, 0, 1],\n",
    "                                  [2, 1, 0]])\n",
    "d.log_prob(order_samples).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"comp_matrix\"].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"comp_probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pos_regret < neg_regret).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug[\"comp_matrix\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_b[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomin = (debug[\"comp_probs\"] * (debug[\"comp_probs\"] - 1) * pos_regret + (1 - debug[\"comp_probs\"]) * (debug[\"comp_probs\"] - 0) * neg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denom = debug[\"comp_probs\"] * pos_regret + (1 - debug[\"comp_probs\"]) * neg_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomin / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "\n",
    "### Reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAG_generation.estimators import reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = torch.FloatTensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n",
    "b = torch.LongTensor([[0, 1, 2],\n",
    "                      [0, 2, 1],\n",
    "                      [1, 2, 0],\n",
    "                      [1, 0, 2],\n",
    "                      [2, 0, 1],\n",
    "                      [2, 1, 0]])\n",
    "thetas = nn.Parameter(torch.FloatTensor([0.0,0.0,0.0]))\n",
    "optim = torch.optim.SGD([thetas], lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    thetas_exp = thetas[None].expand(b.shape[0], -1)\n",
    "    g = reinforce(fb, b, thetas_exp)\n",
    "    print(\"G\", g)\n",
    "    thetas.backward(g.mean(dim=0))\n",
    "    optim.step()\n",
    "    print(\"Thetas\", thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise gradient estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_samples = torch.LongTensor([[0, 1, 2],\n",
    "                                  [0, 2, 1],\n",
    "                                  [1, 2, 0],\n",
    "                                  [1, 0, 2],\n",
    "                                  [2, 0, 1],\n",
    "                                  [2, 1, 0]])\n",
    "pl_thetas = nn.Parameter(torch.FloatTensor([0.02,0.0,-0.02]))\n",
    "prob = torch.FloatTensor([[0.4, 0.6, 0.6],\n",
    "                          [0.4, 0.6, 0.4],\n",
    "                          [0.4, 0.4, 0.4],\n",
    "                          [0.4, 0.4, 0.6],\n",
    "                          [0.4, 0.6, 0.2],\n",
    "                          [0.4, 0.4, 0.2]])\n",
    "logregret = prob.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a matrix for 1[pi_j > pi_i]\n",
    "pos = (F.one_hot(order_samples, order_samples.shape[-1]) * torch.arange(order_samples.shape[-1])[None,:,None]).sum(dim=-2)\n",
    "comp_matrix = (pos[...,None] < pos[...,None,:]).float()\n",
    "print(\"Comp matrix\")\n",
    "print(comp_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a matrix for p(pi_j > pi_i). Dim=0 => theta_j, Dim=1 => theta_i\n",
    "comp_probs = torch.softmax(torch.stack([pl_thetas[None,:].expand(pl_thetas.shape[-1],-1), # theta_i \n",
    "                                        pl_thetas[:,None].expand(-1,pl_thetas.shape[-1])  # theta_j\n",
    "                                        ], dim=-1), dim=-1)[...,1]\n",
    "print(\"Comp probs\")\n",
    "print(comp_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_grads = (comp_probs - comp_matrix)\n",
    "print(\"Comp grads\")\n",
    "print(comp_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomin = logregret * comp_grads\n",
    "denom = logregret\n",
    "\n",
    "print(\"Nomin\")\n",
    "print(nomin)\n",
    "print(\"Denom\")\n",
    "print(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomin, denom = nomin.sum(dim=0), denom.sum(dim=0)\n",
    "denom.masked_fill_(denom == 0.0, 1e-5)\n",
    "\n",
    "pairgrads = nomin / denom \n",
    "\n",
    "print(\"Pair grads\")\n",
    "print(pairgrads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = pairgrads.sum(dim=1) - pairgrads.sum(dim=0)\n",
    "print(\"Grads\", grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Parameter(torch.zeros(3,))\n",
    "optim = torch.optim.Adam([a], lr=1e-3)\n",
    "a.grad = torch.ones(a.shape)\n",
    "optim.step()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
